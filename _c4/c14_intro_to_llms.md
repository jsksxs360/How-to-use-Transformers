---
title: 第十四章：大语言模型技术简介
author: SHENG XU
date: 2024-07-24
category: NLP
layout: post
mathjax: no
---

正如1.2节统计语言发展史所述，在规模扩展定律（Scaling Laws）被证明对语言模型有效之后，研究者构建出了许多大语言模型。尤其是 2022 年底面向普通消费者的 ChatGPT 模型的出现，正式标志着自然语言处理进入大语言模型时代。

本章将简要梳理大语言模型的技术要点以及构建过程，方便读者快速了解如何训练以及使用大语言模型。

## 14.1 大语言模型技术概览

大语言模型能够取得成功主要依赖以下几项关键技术：

**规模扩展**：只有规模达到一定程度模型才会展现出上下文学习、思维链推理等小规模模型不具备的能力。早期的研究主要关注参数规模，例如 OpenAI、Google 等公司提出了一系列分析参数、数据、算力等因素对性能影响的扩展定律（Scaling Laws），并且通过 GPT、PaLM 等模型进行了验证。考虑到使用超大规模数据（如 2T 或 3T 词元）训练十亿级别的模型（如 2B 或 7B）仍然无法达到模型的最大数据容量，最近的工作专注于加大对高质量数据的规模扩展。

**数据工程**：大语言模型的训练方式实际上非常简单，即通过在海量文本上进行下一个词预测的优化，使得模型学习到丰富的语义知识，进而通过文本补全的方式解决各种下游任务，因此模型能力本质上来源于所见过的训练数据。目前数据工程主要关注三个方面：（1）拓宽数据来源；（2）数据清洗；（3）设计有效的数据配比与数据课程，加强对于数据语义信息的利用效率。这三个方面的数据工程技术直接决定了最后大语言模型的性能水平。

**高效预训练**：由于参数规模巨大，大语言模型需要使用各种并行策略以及效率优化方法进行训练，包括 3D 并行（数据并行、流水线并行、张量并行）、ZeRO 内存冗余消除技术等，代表性的分布式训练软件包括 DeepSpeed [4] 和 Megatron-LM [5]，它们能够有效支持千卡甚至万卡的联合训练。此外，在正式训练前通常会开展基于小模型的沙盒测试实验以确定最终的训练策略，并且还需要关注优化技巧以提升训练稳定性和优化效率，如混合精度训练。

> **延伸**
>
> 研究各种训练策略的效果并进行消融实验的成本非常高昂，学术界难以获得充分的算力来系统性研究大语言模型。虽然工业界不断推出开源大模型， 但是对训练过程的开源程度还不够充分，无法了解到许多重要的训练细节。大语言模型非常依赖于工程方法的优化，但是这些技术的理论支撑还比较缺乏。
{: .block-tip }

**能力激发**：为了提升模型的任务求解能力，需要设计合适的指令微调以及提示策略进行激发或诱导。在指令微调方面，可以使用自然语言表达的任务描述以及期望的任务输出对模型进行微调，从而增强模型的通用任务求解能力，提升在未见任务上的泛化能力。在提示学习方面，需要设计合适的提示策略去诱导大语言模型生成正确的问题答案，例如上下文学习、思维链推理等。

> **相关**
>
> 现有的研究大多认为指令微调无法向大语言模型注入新的知识，而是训练大语言模型学会利用自身所掌握的知识与信息进行任务的求解。
{: .block-warning }

**人类对齐**：由于大语言模型可能会生成有偏见、泄露隐私甚至对有害的内容，在实践应用中需要保证大语言模型能够较好地符合人类的价值观。代表性的做法是 OpenAI 公司提出的基于人类反馈的强化学习算法 [RLHF](https://proceedings.neurips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html)（Reinforcement Learning from Human Feedback），将人类偏好引入到大模型的对齐过程中。但是由于强化学习算法的优化过程较为复杂，最近提出了许多监督微调的对齐方式，例如 [DPO](https://proceedings.neurips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html) 算法。最近，OpenAI 公司还发布了“超级对齐”（Super-alignment）项目，研究如何监管具有强人工智能的算法。

> **相关**
>
> 基于人类反馈的强化学习算法（RLHF）的具体做法是：首先训练能够区分模型输出质量好坏的奖励模型，进而使用强化学习算法来指导语言模型对输出行为进行调整，让大语言模型能够生成符合人类预期的输出。
{: .block-warning }

**工具使用**：由于大语言模型在非自然语言形式任务上的能力较为有限，因此可以让模型学会使用各种工具的调用方式，利用合适的工具去实现特定的功能需求，例如可以利用计算器进行精确的数值计算、利用搜索引擎检索最新的时效信息等。在技术路径上，工具调用能力主要是通过指令微调以及提示学习两种途径实现。

## 14.2 大语言模型的构建过程

大语言模型的训练过程可以分为大规模预训练和指令微调与人类对齐两个阶段。

### 14.2.1 大规模预训练

如1.2节统计语言发展史所述，在 BERT 等传统预训练模型中采用的模型架构以及训练任务还比较多样。随着 GPT 模型的成功，“解码器架构 + 预测下一个词”的有效性得到了充分验证，已经成为当前主要的技术路径。

预训练大语言模型需要准备大规模的文本数据，并且进行严格的清洗。由于大语言模型的能力基础主要来源于预训练数据，因此数据的收集（高质量、多源化）与清洗对于模型性能具有重要影响。目前的开源模型大多采用 2∼3T 规模的词元进行预训练，并且正在进一步扩大规模。

预训练过程对于算力的需求量极高，百亿规模的模型一般需要百卡规模的算力集群（如 A100-80G）联合训练数月时间，而千亿模型则需要千卡甚至万卡规模的算力集群。此外，实施过程中涉及到大量经验性技术，如数据如何配比、如何调整学习率、如何及早发现模型的异常行为等，这些细节很多并没有公开发表的经验可循，因此需要研发人员具有丰富的训练经验和异常处理能力。

### 14.2.2 指令微调与人类对齐

由于预训练任务形式所限，预训练后的大语言模型更擅长进行文本补全，并不适合直接解决具体的任务，因此通常还需要对大语言模型进行微调与对齐，使之具备更好的任务求解能力。

目前广泛使用的微调技术是指令微调（Instruction Tuning），又称监督微调（Supervised Fine-tuning, SFT），即通过使用任务输入与输出的配对数据进行训练， 使得语言模型掌握通过问答形式进行任务求解的能力。一般来说，指令微调很难教会大语言模型预训练阶段没有学习到的知识与能力，它主要起到了对于模型能力的激发作用。

与预训练相比，指令微调需要的指令数据规模要小的多，通常数十万到百万规模的指令微调数据就能够有效地激发语言模型的通用任务求解能力，部分工作甚至认为数千条或者数万条高质量指令数据也能达到不错的微调效果。因此，若干台单机八卡（A100-80G）的服务器就能在一天或数天的时间内完成百亿模型的指令微调。这个过程还可以加入多轮次的对话数据来增强模型的人机对话能力。

除了提升任务的解决能力外，还需要将大语言模型与人类的期望、需求以及价值观对齐（Alignment）。代表性方法是 OpenAI 公司提出的基于人类反馈的强化学习对齐方法 RLHF，在指令微调后使用强化学习加强模型的对齐能力。RLHF 算法需要训练一个符合人类价值观的奖励模型（Reward Model），为此需要标注人员针对大语言模型所生成的多条输出进行偏好排序，然后使用偏好数据训练奖励模型。由于强化学习需要维护多个辅助模型进行训练，计算资源消耗通常会多于指令微调， 但是也远小于预训练。目前还有很多工作试图简化对齐过程，通过去除奖励模型或其他使用 SFT 方式来达到与 RLHF 相似的效果。

### 14.2.3 常用的预训练数据集

常用的预训练语料库可以划分为网页、书籍、维基百科、代码以及混合型数据集。

**网页**：网页是大语言模型训练语料中最主要的数据来源，包含新闻报道、博客文章、论坛讨论等各种内容，这些广泛且多元的数据为大语言模型深入理解人类语言提供了重要资源。常用的网页语料库有：

- [Common Crawl](https://commoncrawl.org/)：一个规模庞大、非结构化、多语言的网页数据集，从 2008 年至今一直在定期更新，总数据量达到 PB 级别。一般仅提取特定时间段或者符合特殊要求的子集进行使用。但是该数据集充斥着噪声和低质量数据，在使用前必须进行有效的数据清洗，常用的自动清洗工具有 CCNet 等。
- [C4](https://www.tensorflow.org/datasets/catalog/c4)：Google 构建，基于 2019 年 4 月的 Common Crawl 语料，包括超过 365M 个互联网域，超过 156B 词元，数据量约 800GB。使用该数据集的代表模型有 UL2 和 LLaMA。
- [RedPajama-Data](https://github.com/togethercomputer/RedPajama-Data)：Together AI 构建，包含了来自 Common Crawl 的 100B 份文档，包含英语、法语、西班牙语、德语和意大利语，经过过滤和去重得到约 30T 词元。提供 40 余种预先标注好的数据注释，方便用户根据实际需求筛选数据集。
- [RefinedWeb](https://proceedings.neurips.cc/paper_files/paper/2023/hash/fa3ed726cc5073b9c31e3e49a807789c-Abstract-Datasets_and_Benchmarks.html)：TII 构建，在 2008 年到 2023 年 6 月 Common Crawl 数据上通过筛选和去重构建，共约 5T 词元，开源部分有 600B 词元。是开源大语言模型 Falcon 的主要训练数据集。
- [OpenWebText](https://skylion007.github.io/OpenWebTextCorpus/)：OpenAI WebText 数据集（GPT-2、GPT-3 和 InstructGPT 等均基于该数据集训练）的复现开源版本，首先从 Reddit 上提取网页链接，经过去重、过滤等处理，最终保留来自约 8M 份文档的 38GB 文本数据。

> **相关**
>
> 在上述网页数据集中，中文网页占比通常非常低，因此不足以训练中文大语言模型。下面介绍一些具有代表性的中文网页数据集。
>
> - [ChineseWebText](https://arxiv.org/abs/2311.01149)：中科院自动化所构建，从 Common Crawl 数据中精心筛选的中文数据集。汇集了 2021 年至 2023 年间的网页快照，总计 1.42TB 数据量。还特别发布了一个 600GB 大小的中文数据子集，并配套推出了一 款名为 EvalWeb 的数据清洗工具
> - [WanJuan](https://arxiv.org/abs/2308.10755)：上海人工智能实验室构建，由网页、书籍等数据组成，约 500M 个文档，数据大小超过 1TB。将多种格式的数据进行了统 一，并进行了细粒度的清洗和去重。
{: .block-warning }

**书籍**：书籍是人类知识与文化的重要载体，并且内容主要是长文本，能够帮助语言模型学习语言的长程依赖关系，并深入理解语言的内在逻辑与表达习惯。书籍的语言表达通常更为严谨，整体上质量较高，并且能够覆盖多元化的知识体系。常用的书籍语料库有：

- [BookCorpusOpen](https://openaccess.thecvf.com/content_iccv_2015/papers/Zhu_Aligning_Books_and_ICCV_2015_paper.pdf)：University of Toronto & MIT 构建的 BookCorpus 数据集（被 GPT、GPT-2、LLaMA 等模型使用）的镜像版本，包含了共计 17,868 本书籍。
- [arXiv Dataset](https://arxiv.org/abs/1905.00075)：arXiv 官方发布的论文数据集，广泛涵盖了物理、数学和计算机科学等领域的论文，共包含约 1.7M 篇预印本文章，总数据量约为 1.1TB。
- [S2ORC](https://aclanthology.org/2020.acl-main.447/)：Allen Institute for AI 基于学术搜索引擎 Semantic Scholar 上的论文构建，论文经过了清洗、过滤并被处理成适合预训练的格式。该数据集还有一个衍生数据集 [peS2o](https://github.com/allenai/pes2o)，v2 版本共计包含了约 42B 词元。

**维基百科**：维基百科（Wikipedia）是一个综合性的在线百科全书，提供了高质量的知识信息文章。维基百科数据具有以下几个特点：（1）专业性：维基百科条目通常具有良好的结构性和权威性，不仅对于各种专业术语和概念进行了阐释，还揭示了它们在不同领域的应用和联系；（2）多语性：维基百科支持英语、汉语、 法语、德语等一共 300 多种语言，是一个宝贵的多语言平行语料库；（3）实时性：维基百科的内容在不断更新，对于知识信息的实时性维护较为及时，并且会定期发布其数据库的[打包副本](https://dumps.wikimedia.org/)。

**代码**：代码具有高度结构化与专业性，引入包含代码的数据集可以增强模型的结构化推理能力与长程逻辑关系，能够提升模型理解和生成编程语言的能力。现有的工作主要从互联网上爬取具有开源许可的代码，两个主要来源是公共代码仓库（例如 GitHub）和代码相关的问答平台（例如 StackOverflow）。常用的代码语料库有：

- [BigQuery](https://cloud.google.com/bigquery/public-data?hl=zh-cn)：谷歌构建的企业数据仓库，包含了众多领域的公共数据集，其中的代码类数据覆盖各种编程语言。CodeGen 即抽取了其中的公开代码数据子集进行训练。
- [The Stack](https://arxiv.org/abs/2211.15533v1)：Hugging Face 构建，涵盖了 30 种编程语言，数据来源于 GHArchive 项目中的 GitHub 活跃仓库，经过数据筛选、过滤以及许可证检测等处理后，最终数据量约为 3TB。v1.2 版本已扩展到 358 种编程语言，数据量约为 6TB。
- [StarCoder](https://arxiv.org/abs/2305.06161)：BigCode 基于 The Stack v1.2 进一步处理后的代码数据集，筛选出了 86 种语言，同时还进行了人工抽样审核以确认数据为人类编写的正常代码，最终数据总量约为 783GB。

**混合型数据集**：为了便于研发人员使用，很多研究机构对于多种来源的数据集合进行了混合，发布了一系列包括多来源的文本数据集合。这些混合数据集往往融合了新闻、社交媒体内容、维基百科条目等各种类型的文本，减少了重复清洗数据、选择数据的繁重工程。常用的混合语料库有：

- [The Pile](https://arxiv.org/abs/2101.00027)：EleutherAI 构建，数据包括书籍、网站、代码、科学论文和社交媒体等。由 22 个多样化的高质量子集混合而成，包括OpenWebText、维基百科等，最终总数据量约为 825GB。GPT-J、CodeGen、Megatron-Turing NLG 等模型都用到该数据集。
- [ROOTS](https://proceedings.neurips.cc/paper_files/paper/2022/hash/ce9e92e3de2372a4b93353eb7f3dc0bd-Abstract-Datasets_and_Benchmarks.html)：BigScience 构建，约 62% 的数据来源于整理好的自然语言处理数据集及相关文档、利用 Common Crawl 收集的网页数据以及 GitHub 代码数据，约 38% 的数据来源于一个网页爬虫项目 OSCAR，并对其进行了过滤、去重和个人信息移除。包含 46 种自然语言（英语占比约为 30%）以及 13 种编程语言（Java、PHP 和 C++ 占比过半），总数据量约为 1.6TB。
- [Dolma](https://arxiv.org/abs/2402.00159)：Allen Institute for AI 构建，包括来自 Common Crawl 的网页、Semantic Scholar 学术论文、GitHub 代码、书籍、Reddit 的社交媒体帖子以及维基百科数据，由来自大约 200TB 原始文本的 3T 个词元组成。v1.6 的版本文件大小约为 5.4TB。开源大语言模型 OLMo 即使用该数据训练。

### 14.2.4 常用微调数据集

微调主要涉及指令微调（有监督微调）和对齐微调，下面将列举一些可用于微调的数据集。

**指令微调数据集**：按照指令实例的构建方法可以将指令微调数据集分为自然语言处理任务数据集、日常对话数据集和合成数据集。（1）自然语言处理任务数据集一般是在有监督的多任务训练数据集（包含多个自然语言处理任务实例）上通过人工编写任务描述来构建；（2）日常对话数据集则是基于真实用户对话构建，其中查询主要由真实用户提出、回复则由人类标注或者语言模型生成，对话类型通常包括开放式生成、问答、头脑风暴和聊天；（3）合成数据集则通常是使用大语言模型基于预定义的规则或方法进行构建。一些具有代表性的指令微调数据集如表 14-2 所示。常用的指令微调数据集有：

- [P3](https://arxiv.org/abs/2110.08207)（Public Pool of Prompts）：BigScience 构建，由超过 270 个自然语言处理任务数据集和 2000 多种提示整合而成（每个任务可能不止一种提示），全面涵盖多选问答、提取式问答、情感分类、文本摘要、自然语言推断等任务。其子集被用来训练 T0 模型。
- [FLAN](https://dl.acm.org/doi/abs/10.5555/3618408.3619349)：Google 构建，v2 版本主要由 Muffin、NIV2、T0-SF 和 CoT 四个子集构成。其中 Muffin 由 v1 版本的 62 个任务和新加入的 26 个任务组成（包括对话数据和代码合成数据）；T0-SF 则是从 T0 模型的数据中抽取出来，同时确保与 Muffin 不重叠；NIV2 指的是数据集 Natural-Instructions v2；CoT 则是为了增强模型的推理能力而加入的九种不同推理任务的组合。FLAN-v2 对每项任务都设置了最大上限，防止某些任务在采样中占主导地位。FLAN 论文显示使用 52% Muffin、15% T0-SF、3% CoT 以及 30% NIV2 这一混合比例通常能够使得模型具有较好表现。
- [ShareGPT](https://sharegpt.com/)：TechCrunch 发布的对话数据集，数据来源于开源平台 ShareGPT，语种主要为英语和其他西方语言，其中查询来自于用户的真实提问或指令，回复则是 ChatGPT 对此生成的回答。
- [OpenAssistant](https://proceedings.neurips.cc/paper_files/paper/2023/hash/949f0f8f32267d297c2d4e3ee10a2e7e-Abstract-Datasets_and_Benchmarks.html)：LAION-AI 人工构建的多语言对话语料库，共有 91,829 条用户提示，69,614 条回复，包含 35 种语言并且附有人工标注的质量评级（例如回复的有用性、无害性等）。
- [Dolly](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)：Databricks 构建的对话数据集，包含 15000 个人类生成的数据实例，主题涉及 InstructGPT 论文中提到的 7 个领域，包括头脑风暴、分类、封闭/开放式质量保证、生成、信息提取等。
- [Self-Instruct-52K](https://aclanthology.org/2023.acl-long.754/)：University of Washington 使用 Self-Instruct 方法生成的英语指令数据集，包含 52K 条指令以及 82K 个实例输入和输出。最初由人工收集创建了 175 个种子任务，每个任务包括 1 个指令和 1 个包含输入输出的实例。然后，每次随机抽取 8 个指令作为示例，引导 GPT-3 模型生成新的指令以及对应的输入和输出，经过滤后添加到数据集中。迭代上述过程，最终获得了 52K 条指令和 82K 个实例数据。
- [Alpaca-52K](https://github.com/tatsu-lab/stanford_alpaca)：同样基于 Self-Instruct 方法进行构建的，在 Self-Instruct-52K 的 175 个种子任务上利用 OpenAI 的 text-davinci-003 模型获得了 52K 个不重复的指令，并根据指令和输入生成输出，每条指令仅对应于一个输入输出实例（输入可选，最终数据中只有 40% 具有输入）。

> **相关**
>
> 如果你不了解 Self-Instruct 方法不用着急，本教程会在第十六章《使用大语言模型》中进行详细介绍。
{: .block-warning }

**人类对齐数据集**：对齐目标一般聚焦于有用性、诚实性和无害性三个方面，下面将介绍几个代表性的对齐微调数据集，它们各自针对上 述对齐目标进行了标注。

- [HH-RLHF](https://arxiv.org/abs/2204.05862)：Anthropic 构建，关注大语言模型的有用性和无害性。包含约 169K 个开放式对话，涉及人类向智能助手寻求帮助、建议或请求完成任务等情景。信息助手将为每个查询提供两个回复，一个回复被选择而另一个被拒绝。有用性相关数据中，被认为更有用的回复将被选择；而无害性相关数据中，被认为更有害的回复将被选择。
- [SHP](https://proceedings.mlr.press/v162/ethayarajh22a.html)：Standfordnlp 构建，关注模型的有用性。包含 385K 个数据实例，对从烹饪到法律建议等 18 个不同主题领域中问题/指令的人类偏好进行标注，每个实例都基于寻求帮助的 Reddit 帖子构建的，包含问题以及帖子下两个排名较高的评论，其中一个被 Reddit 用户认为更有用，另一个被认为不太有帮助。
- [Stack Exchange Preferences](https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences)：HuggingFace 构建，关注模型的有用性。涵盖来自编程问答社区 Stack Overflow 的约 10M 个问题和答案，每个实例均包含一个问题以及不少于两个候选答案，每个答案都附有一个根据投票数计算出的分数并附带是否被选中的标签。
- [Sandbox Alignment Data](https://arxiv.org/abs/2305.16960)：Google 构建，致力于运用模型自身的反馈机制标注数据，关注模型的有用性、诚实性、无害性。数据源自模拟人类社交互动场景的 SANDBOX 虚拟环境，在该环境中，多个大语言模型根据问题给出回复然后互相“交流”，并根据彼此的反馈来不断修正和完善自己的回复。该数据集涵盖 169K 个实例，每个实例均包含一个查询、多个回复选项以及由其他模型给出的相应评分。

## 14.3 开发大语言模型

开发大语言模型是一项复杂的工程，涉及到包括并行策略以及效率优化方法在内的各种工程技巧，因此一些公司以及研究机构推出了专用于开发大语言模型的代码库以推动该领域的发展。下面将介绍具有代表性的两个代码库。

### 14.3.1 DeepSpeed 库

[DeepSpeed](https://dl.acm.org/doi/abs/10.1145/3394486.3406703) 由微软公司开发，是一个旨在加速模型训练的高性能库，被广泛用于大语言模型的分布式训练。

DeepSpeed 为分布式训练提供了各种优化技术支持，如内存优化（ZeRO 技术、梯度检查点）、数据并行、混合精度训练等，使得整个训练过程变得更加高效和稳定。为了更适配用户需求，DeepSpeed 针对模型生成和强化学习分别开发了特制的优化框架：DeepSpeed-MII 和 DeepSpeed-Chat。

**DeepSpeed-MII**：通过提高吞吐量、降低延迟等方式来降低大模型解码生成的运行成本。DeepSpeed-MII 首先实现了块状键值缓存和连续批处理技术加速文本生成过程，然后又提出了 SplitFuse 技术将提示和生成结果进行动态分解以进一步改善连续批处理和系统吞吐量。目前已支持包括 LLaMA 、Mistral 、Falcon、 Mixtral 和 Qwen 在内的多个模型。

**DeepSpeed-Chat**：用于训练类 ChatGPT 模型的开发工具，完整集成了包括基于人类反馈的强化学习（RLHF）算法在内的训练过程。它具有三个主要功能：（1）简化了类 ChatGPT 模型的训练和生成过程，用户可以用简单的脚本实现多个训练步骤，并且提供了用于测试对话式交互的 API；（2）复现了 InstructGPT 的训练过程，包括有监督微调、奖励模型训练和基于人类反馈的强化学习，还提供了数据抽象和混合功能；（3）将训练和生成集成到了统一框架中，实现了在 RLHF 中训练和生成模式之间的无缝切换。

### 14.3.2 Megatron-LM 库

[Megatron-LM](https://arxiv.org/abs/1909.08053) 是由 NVIDIA 公司开发的一款专门为训练大语言模型而设计的代码库，旨在解决大型模型训练过程中所遇到的一系列技术挑战，包括显存限制、 计算效率以及不同的并行策略带来的通信问题。

Megatron-LM 引入了一系列分布式训练的优化技巧，支持多种并行策略，包括（1）数据并行，通过在每个工作节点复制模型，并将输入数据切分多份分配给多个节点，定期同步所有梯度来提升 GPU 的使用效率；（2）模型并行，包括张量并行和流水线并行，通过在多个工作节点上分配模型和计算来克服单个 GPU 容量限制的问题。此外，Megatron-LM 还支持混合精度训练和 FlashAttention 功能。这些优 化技术可以在很大程度上提高训练效率和速度，实现跨 GPU 的高效分布式训练。 

## 14.4 小结

本章简要介绍了大语言模型的技术要点以及构建过程，并且列举了可用于预训练以及微调模型的常用数据集，最后还介绍了目前开发大语言模型常用的代码库。

在下面的章节中，本教程将对预训练以及微调过程进行更详细的介绍，并带领大家实际上手微调多个大语言模型。

## 参考

[[1]](https://llmbook-zh.github.io/) 赵鑫等.2024.大语言模型